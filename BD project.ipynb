{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20bab1e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'machine_learning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expr\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmachine_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluateModel\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmachine_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trainModel\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'machine_learning'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import expr\n",
    "from machine_learning.testing import evaluateModel\n",
    "from machine_learning.training import trainModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97cc910c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'$oid': '5a132293741a2384e8376cbc'}</td>\n",
       "      <td>A19PBP93OF896</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Alinna Satake \"Can't Stop Eating\"</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>My 3-yr-old daughter received this as a gift f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tiny and Poorly Constructed!</td>\n",
       "      <td>1363824000</td>\n",
       "      <td>03 21, 2013</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'$oid': '5a132293741a2384e8376cb9'}</td>\n",
       "      <td>A2G0LNLN79Q6HR</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>aj_18 \"Aj_18\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This was a really cute tutu the only problem i...</td>\n",
       "      <td>4</td>\n",
       "      <td>Really Cute but rather short.</td>\n",
       "      <td>1337990400</td>\n",
       "      <td>05 26, 2012</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'$oid': '5a132293741a2384e8376cba'}</td>\n",
       "      <td>A2XVJBSRI3SWDI</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>abigail</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Perfect red tutu for the price. I baught it as...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice tutu</td>\n",
       "      <td>1383523200</td>\n",
       "      <td>11 4, 2013</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'$oid': '5a132293741a2384e8376cbd'}</td>\n",
       "      <td>A1P0IHU93EF9ZK</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Bought it for my daughters first birthday whic...</td>\n",
       "      <td>4</td>\n",
       "      <td>i love it</td>\n",
       "      <td>1390435200</td>\n",
       "      <td>01 23, 2014</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'$oid': '5a132293741a2384e8376cbe'}</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Amazon Customer \"cameramom\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great tutu-  not cheaply made</td>\n",
       "      <td>1297468800</td>\n",
       "      <td>02 12, 2011</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>{'$oid': '5a132293741a2384e8379553'}</td>\n",
       "      <td>A105HX4CY4GFS6</td>\n",
       "      <td>B00007GDAL</td>\n",
       "      <td>Karee</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>this has 16 card slots, one is a window thumb ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Perfect for me</td>\n",
       "      <td>1373932800</td>\n",
       "      <td>07 16, 2013</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>{'$oid': '5a132293741a2384e8379560'}</td>\n",
       "      <td>APAC4K0A9LBJJ</td>\n",
       "      <td>B00007GDAL</td>\n",
       "      <td>Lainee,E</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I'm very satisfied with this wallet.  Quality ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Good Product</td>\n",
       "      <td>1396224000</td>\n",
       "      <td>03 31, 2014</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>{'$oid': '5a132293741a2384e837955f'}</td>\n",
       "      <td>AC6C1VKYQBELX</td>\n",
       "      <td>B00007GDAL</td>\n",
       "      <td>Lady Sheep</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I really like the wallet, I like that it is al...</td>\n",
       "      <td>5</td>\n",
       "      <td>great wallet</td>\n",
       "      <td>1378771200</td>\n",
       "      <td>09 10, 2013</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>{'$oid': '5a132293741a2384e837955d'}</td>\n",
       "      <td>A17OBB1HKHY1KP</td>\n",
       "      <td>B00007GDAL</td>\n",
       "      <td>Kimberly M</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've been looking for something like this fore...</td>\n",
       "      <td>5</td>\n",
       "      <td>Finally</td>\n",
       "      <td>1402617600</td>\n",
       "      <td>06 13, 2014</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>{'$oid': '5a132293741a2384e837955e'}</td>\n",
       "      <td>A26KOQFEU2VPW2</td>\n",
       "      <td>B00007GDAL</td>\n",
       "      <td>K. Petuskey \"Aging reader\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I found the wallet with all card slots filled ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Bulky</td>\n",
       "      <td>1395964800</td>\n",
       "      <td>03 28, 2014</td>\n",
       "      <td>Clothing_Shoes_and_Jewelry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       _id      reviewerID        asin  \\\n",
       "0     {'$oid': '5a132293741a2384e8376cbc'}   A19PBP93OF896  0000031887   \n",
       "1     {'$oid': '5a132293741a2384e8376cb9'}  A2G0LNLN79Q6HR  0000031887   \n",
       "2     {'$oid': '5a132293741a2384e8376cba'}  A2XVJBSRI3SWDI  0000031887   \n",
       "3     {'$oid': '5a132293741a2384e8376cbd'}  A1P0IHU93EF9ZK  0000031887   \n",
       "4     {'$oid': '5a132293741a2384e8376cbe'}  A1KLRMWW2FWPL4  0000031887   \n",
       "...                                    ...             ...         ...   \n",
       "9995  {'$oid': '5a132293741a2384e8379553'}  A105HX4CY4GFS6  B00007GDAL   \n",
       "9996  {'$oid': '5a132293741a2384e8379560'}   APAC4K0A9LBJJ  B00007GDAL   \n",
       "9997  {'$oid': '5a132293741a2384e837955f'}   AC6C1VKYQBELX  B00007GDAL   \n",
       "9998  {'$oid': '5a132293741a2384e837955d'}  A17OBB1HKHY1KP  B00007GDAL   \n",
       "9999  {'$oid': '5a132293741a2384e837955e'}  A26KOQFEU2VPW2  B00007GDAL   \n",
       "\n",
       "                           reviewerName helpful  \\\n",
       "0     Alinna Satake \"Can't Stop Eating\"  [0, 1]   \n",
       "1                         aj_18 \"Aj_18\"  [1, 1]   \n",
       "2                               abigail  [0, 0]   \n",
       "3                                Amanda  [0, 0]   \n",
       "4           Amazon Customer \"cameramom\"  [0, 0]   \n",
       "...                                 ...     ...   \n",
       "9995                              Karee  [1, 1]   \n",
       "9996                           Lainee,E  [0, 0]   \n",
       "9997                         Lady Sheep  [1, 1]   \n",
       "9998                         Kimberly M  [0, 0]   \n",
       "9999         K. Petuskey \"Aging reader\"  [0, 0]   \n",
       "\n",
       "                                             reviewText  overall  \\\n",
       "0     My 3-yr-old daughter received this as a gift f...        1   \n",
       "1     This was a really cute tutu the only problem i...        4   \n",
       "2     Perfect red tutu for the price. I baught it as...        5   \n",
       "3     Bought it for my daughters first birthday whic...        4   \n",
       "4     This is a great tutu and at a really great pri...        5   \n",
       "...                                                 ...      ...   \n",
       "9995  this has 16 card slots, one is a window thumb ...        5   \n",
       "9996  I'm very satisfied with this wallet.  Quality ...        5   \n",
       "9997  I really like the wallet, I like that it is al...        5   \n",
       "9998  I've been looking for something like this fore...        5   \n",
       "9999  I found the wallet with all card slots filled ...        3   \n",
       "\n",
       "                            summary  unixReviewTime   reviewTime  \\\n",
       "0      Tiny and Poorly Constructed!      1363824000  03 21, 2013   \n",
       "1     Really Cute but rather short.      1337990400  05 26, 2012   \n",
       "2                         Nice tutu      1383523200   11 4, 2013   \n",
       "3                         i love it      1390435200  01 23, 2014   \n",
       "4     Great tutu-  not cheaply made      1297468800  02 12, 2011   \n",
       "...                             ...             ...          ...   \n",
       "9995                 Perfect for me      1373932800  07 16, 2013   \n",
       "9996                   Good Product      1396224000  03 31, 2014   \n",
       "9997                   great wallet      1378771200  09 10, 2013   \n",
       "9998                        Finally      1402617600  06 13, 2014   \n",
       "9999                          Bulky      1395964800  03 28, 2014   \n",
       "\n",
       "                        category  class  \n",
       "0     Clothing_Shoes_and_Jewelry      0  \n",
       "1     Clothing_Shoes_and_Jewelry      1  \n",
       "2     Clothing_Shoes_and_Jewelry      1  \n",
       "3     Clothing_Shoes_and_Jewelry      1  \n",
       "4     Clothing_Shoes_and_Jewelry      1  \n",
       "...                          ...    ...  \n",
       "9995  Clothing_Shoes_and_Jewelry      1  \n",
       "9996  Clothing_Shoes_and_Jewelry      1  \n",
       "9997  Clothing_Shoes_and_Jewelry      1  \n",
       "9998  Clothing_Shoes_and_Jewelry      1  \n",
       "9999  Clothing_Shoes_and_Jewelry      0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_json('Clothing_Shoes_and_Jewelry.json',nrows=10000,lines=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563902e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/09 16:23:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"spark://localhost:7077\").appName(\"BD\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "476e0fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===================================================>    (22 + 2) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|                 _id|      asin|            category|class|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|         textSummary|unixReviewTime|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  0.0| [0, 1]|    1.0|My 3-yr-old daugh...|03 21, 2013| A19PBP93OF896|Alinna Satake \"Ca...|Tiny and Poorly C...|    1363824000|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [1, 1]|    4.0|This was a really...|05 26, 2012|A2G0LNLN79Q6HR|       aj_18 \"Aj_18\"|Really Cute but r...|    1337990400|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Perfect red tutu ...| 11 4, 2013|A2XVJBSRI3SWDI|             abigail|           Nice tutu|    1383523200|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|Bought it for my ...|01 23, 2014|A1P0IHU93EF9ZK|              Amanda|           i love it|    1390435200|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|This is a great t...|02 12, 2011|A1KLRMWW2FWPL4|Amazon Customer \"...|Great tutu-  not ...|    1297468800|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Got this for our ...|12 26, 2012|A1GQPAM8Y45QN7|     Amazon Customer|                Tutu|    1356480000|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  0.0| [1, 1]|    2.0|the tutu color wa...|02 17, 2013|A2R3K1KX09QBYP|      alert consumer|not very good mat...|    1361059200|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Just as described...|06 22, 2013| AEAN37KUOYSX4|     Amazon Customer|          Fantastic!|    1371859200|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|I bought this for...|01 19, 2013|A2G5TCU2WDFZ65|     Amazon Customer|         Very Cute!!|    1358553600|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|This really is a ...| 03 4, 2013|A2QEODSEIT1ME2|     Amazon Customer|           Very Nice|    1362355200|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [3, 4]|    4.0|I ordered this fo...|03 16, 2010|A3Q6CTO56DJ8UZ|      Amazing Amazon|       Good Quality!|    1268697600|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Vey cute and perf...|02 18, 2014|A3CHBY0CB0O7PP|     Amazon Customer|                cute|    1392681600|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Loved it and so d...|11 21, 2012|A1Z4XQ937SMPO3|             amstier|        super cute!!|    1353456000|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Purchased it for ...|06 16, 2014|A1MCJONUQ78L9T|     Amazon Customer|My daughter loved...|    1402876800|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|Very cute, shorte...|12 10, 2013|A2PSIVW9I3TGHD|     Amazon Customer|        Good product|    1386633600|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Our 3-year-old pe...|08 24, 2013| AZMKXP68HZ4CN|      Angela K. Ford|          Wonderful!|    1377302400|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  0.0| [0, 0]|    3.0|The waistband was...|12 28, 2012| A5GPS8FCXTPPI|          Ann C Peat|           Waistband|    1356652800|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|The tutu's was fo...|01 15, 2014| AM1CYMR007O6H|         anne foster|              Tutus!|    1389744000|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|My 5 year old dau...|12 25, 2013|A25G580SJ513IC|          Anne Klein|         Very happy!|    1387929600|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|I just got this t...|10 24, 2013|A2F9MVWWC0IZYW|                 Amy|Perfect for the p...|    1382572800|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('Clothing_Shoes_and_Jewelry.json')\n",
    "df = df.withColumnRenamed(\"summary\",\"textSummary\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c4829a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(20,[0,1,2,3,4,5,...|\n",
      "|  1.0|(20,[0,1,2,3,6,7,...|\n",
      "|  1.0|(20,[0,3,4,6,8,9,...|\n",
      "|  1.0|(20,[1,2,3,4,5,6,...|\n",
      "|  1.0|(20,[0,1,2,3,4,5,...|\n",
      "|  1.0|(20,[1,2,3,4,5,6,...|\n",
      "|  0.0|(20,[0,1,3,4,5,6,...|\n",
      "|  1.0|(20,[0,1,3,4,6,7,...|\n",
      "|  1.0|(20,[0,1,2,3,4,5,...|\n",
      "|  1.0|(20,[1,3,4,5,6,7,...|\n",
      "|  1.0|(20,[1,2,3,4,5,6,...|\n",
      "|  1.0|(20,[1,3,4,6,7,8,...|\n",
      "|  1.0|(20,[0,2,3,6,8,9,...|\n",
      "|  1.0|(20,[0,1,2,3,4,5,...|\n",
      "|  1.0|(20,[0,1,2,3,4,5,...|\n",
      "|  1.0|(20,[2,3,4,5,6,8,...|\n",
      "|  0.0|(20,[1,2,3,4,5,6,...|\n",
      "|  1.0|(20,[0,3,4,6,8,9,...|\n",
      "|  1.0|(20,[0,1,3,4,5,6,...|\n",
      "|  1.0|(20,[0,1,2,3,4,5,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b8cae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|                 _id|      asin|            category|class|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|               words|         rawFeatures|            features|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  0.0| [0, 1]|    1.0|My 3-yr-old daugh...|03 21, 2013| A19PBP93OF896|Alinna Satake \"Ca...|Tiny and Poorly C...|    1363824000|[my, 3-yr-old, da...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [1, 1]|    4.0|This was a really...|05 26, 2012|A2G0LNLN79Q6HR|       aj_18 \"Aj_18\"|Really Cute but r...|    1337990400|[this, was, a, re...|(20,[0,1,2,3,6,7,...|(20,[0,1,2,3,6,7,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Perfect red tutu ...| 11 4, 2013|A2XVJBSRI3SWDI|             abigail|           Nice tutu|    1383523200|[perfect, red, tu...|(20,[0,3,4,6,8,9,...|(20,[0,3,4,6,8,9,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|Bought it for my ...|01 23, 2014|A1P0IHU93EF9ZK|              Amanda|           i love it|    1390435200|[bought, it, for,...|(20,[1,2,3,4,5,6,...|(20,[1,2,3,4,5,6,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|This is a great t...|02 12, 2011|A1KLRMWW2FWPL4|Amazon Customer \"...|Great tutu-  not ...|    1297468800|[this, is, a, gre...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Got this for our ...|12 26, 2012|A1GQPAM8Y45QN7|     Amazon Customer|                Tutu|    1356480000|[got, this, for, ...|(20,[1,2,3,4,5,6,...|(20,[1,2,3,4,5,6,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  0.0| [1, 1]|    2.0|the tutu color wa...|02 17, 2013|A2R3K1KX09QBYP|      alert consumer|not very good mat...|    1361059200|[the, tutu, color...|(20,[0,1,3,4,5,6,...|(20,[0,1,3,4,5,6,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Just as described...|06 22, 2013| AEAN37KUOYSX4|     Amazon Customer|          Fantastic!|    1371859200|[just, as, descri...|(20,[0,1,3,4,6,7,...|(20,[0,1,3,4,6,7,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|I bought this for...|01 19, 2013|A2G5TCU2WDFZ65|     Amazon Customer|         Very Cute!!|    1358553600|[i, bought, this,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|This really is a ...| 03 4, 2013|A2QEODSEIT1ME2|     Amazon Customer|           Very Nice|    1362355200|[this, really, is...|(20,[1,3,4,5,6,7,...|(20,[1,3,4,5,6,7,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [3, 4]|    4.0|I ordered this fo...|03 16, 2010|A3Q6CTO56DJ8UZ|      Amazing Amazon|       Good Quality!|    1268697600|[i, ordered, this...|(20,[1,2,3,4,5,6,...|(20,[1,2,3,4,5,6,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Vey cute and perf...|02 18, 2014|A3CHBY0CB0O7PP|     Amazon Customer|                cute|    1392681600|[vey, cute, and, ...|(20,[1,3,4,6,7,8,...|(20,[1,3,4,6,7,8,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Loved it and so d...|11 21, 2012|A1Z4XQ937SMPO3|             amstier|        super cute!!|    1353456000|[loved, it, and, ...|(20,[0,2,3,6,8,9,...|(20,[0,2,3,6,8,9,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Purchased it for ...|06 16, 2014|A1MCJONUQ78L9T|     Amazon Customer|My daughter loved...|    1402876800|[purchased, it, f...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|Very cute, shorte...|12 10, 2013|A2PSIVW9I3TGHD|     Amazon Customer|        Good product|    1386633600|[very, cute,, sho...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Our 3-year-old pe...|08 24, 2013| AZMKXP68HZ4CN|      Angela K. Ford|          Wonderful!|    1377302400|[our, 3-year-old,...|(20,[2,3,4,5,6,8,...|(20,[2,3,4,5,6,8,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  0.0| [0, 0]|    3.0|The waistband was...|12 28, 2012| A5GPS8FCXTPPI|          Ann C Peat|           Waistband|    1356652800|[the, waistband, ...|(20,[1,2,3,4,5,6,...|(20,[1,2,3,4,5,6,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|The tutu's was fo...|01 15, 2014| AM1CYMR007O6H|         anne foster|              Tutus!|    1389744000|[the, tutu's, was...|(20,[0,3,4,6,8,9,...|(20,[0,3,4,6,8,9,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|My 5 year old dau...|12 25, 2013|A25G580SJ513IC|          Anne Klein|         Very happy!|    1387929600|[my, 5, year, old...|(20,[0,1,3,4,5,6,...|(20,[0,1,3,4,5,6,...|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|I just got this t...|10 24, 2013|A2F9MVWWC0IZYW|                 Amy|Perfect for the p...|    1382572800|[i, just, got, th...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rescaledData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd05901a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: <bound method DataFrame.summary of DataFrame[_id: struct<$oid:string>, asin: string, category: string, class: double, helpful: array<bigint>, overall: double, reviewText: string, reviewTime: string, reviewerID: string, reviewerName: string, summary: string, unixReviewTime: bigint]> of type <class 'method'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Word2Vec\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Input data: Each row is a bag of words from a sentence or document.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m l \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m      5\u001b[0m documentDF \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(data\u001b[38;5;241m=\u001b[39ml, schema \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m documentDF\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pyspark/sql/functions.py:3224\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(str, pattern, limit)\u001b[0m\n\u001b[1;32m   3191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mstr\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m, pattern: \u001b[38;5;28mstr\u001b[39m, limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m   3192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3193\u001b[0m \u001b[38;5;124;03m    Splits str around matches of the given pattern.\u001b[39;00m\n\u001b[1;32m   3194\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3222\u001b[0m \u001b[38;5;124;03m    [Row(s=['one', 'two', 'three', ''])]\u001b[39;00m\n\u001b[1;32m   3223\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _invoke_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43m_to_java_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m, pattern, limit)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pyspark/sql/column.py:65\u001b[0m, in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     63\u001b[0m     jcol \u001b[38;5;241m=\u001b[39m _create_column_from_name(col)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument, not a string or column: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor column literals, use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstruct\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_map\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(col, \u001b[38;5;28mtype\u001b[39m(col))\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jcol\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid argument, not a string or column: <bound method DataFrame.summary of DataFrame[_id: struct<$oid:string>, asin: string, category: string, class: double, helpful: array<bigint>, overall: double, reviewText: string, reviewTime: string, reviewerID: string, reviewerName: string, summary: string, unixReviewTime: bigint]> of type <class 'method'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "# Word2Vec\n",
    "\n",
    "# Input data: Each row is a bag of words from a sentence or document.\n",
    "l = df.select('class',split(df.reviewText, ' ').alias('str')).take(10000)\n",
    "documentDF = spark.createDataFrame(data=l, schema = ['class','str'])\n",
    "documentDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26f15e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                 str|\n",
      "+-----+--------------------+\n",
      "|  0.0|[Tiny, and, Poorl...|\n",
      "|  1.0|[Really, Cute, bu...|\n",
      "|  1.0|        [Nice, tutu]|\n",
      "|  1.0|       [i, love, it]|\n",
      "|  1.0|[Great, tutu-, , ...|\n",
      "|  1.0|              [Tutu]|\n",
      "|  0.0|[not, very, good,...|\n",
      "|  1.0|        [Fantastic!]|\n",
      "|  1.0|      [Very, Cute!!]|\n",
      "|  1.0|        [Very, Nice]|\n",
      "|  1.0|    [Good, Quality!]|\n",
      "|  1.0|              [cute]|\n",
      "|  1.0|     [super, cute!!]|\n",
      "|  1.0|[My, daughter, lo...|\n",
      "|  1.0|     [Good, product]|\n",
      "|  1.0|        [Wonderful!]|\n",
      "|  0.0|         [Waistband]|\n",
      "|  1.0|            [Tutus!]|\n",
      "|  1.0|      [Very, happy!]|\n",
      "|  1.0|[Perfect, for, th...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input data: Each row is a bag of words from a sentence or document.\n",
    "documentDF = df.select('class',split(df.textSummary, ' ').alias('str'))\n",
    "documentDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "840589cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Learn a mapping from words to Vectors.\n",
    "word2Vec = Word2Vec(vectorSize=7, minCount=0, inputCol=\"str\", outputCol=\"result\")\n",
    "model = word2Vec.fit(documentDF)\n",
    "\n",
    "result = model.transform(documentDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae992d29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|class|                 str|              result|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|[Tiny, and, Poorl...|[-0.1789312288165...|\n",
      "|  1.0|[Really, Cute, bu...|[-0.2102354392409...|\n",
      "|  1.0|        [Nice, tutu]|[-0.1598797589540...|\n",
      "|  1.0|       [i, love, it]|[0.89725091060002...|\n",
      "|  1.0|[Great, tutu-, , ...|[-0.1689084346095...|\n",
      "|  1.0|              [Tutu]|[0.02656632661819...|\n",
      "|  0.0|[not, very, good,...|[-0.3106276933103...|\n",
      "|  1.0|        [Fantastic!]|[0.07304732501506...|\n",
      "|  1.0|      [Very, Cute!!]|[-0.7205476164817...|\n",
      "|  1.0|        [Very, Nice]|[-0.6041751354932...|\n",
      "|  1.0|    [Good, Quality!]|[-0.7159929871559...|\n",
      "|  1.0|              [cute]|[-0.5383317470550...|\n",
      "|  1.0|     [super, cute!!]|[-0.4520824253559...|\n",
      "|  1.0|[My, daughter, lo...|[1.40153291821479...|\n",
      "|  1.0|     [Good, product]|[-0.4305349886417...|\n",
      "|  1.0|        [Wonderful!]|[0.10528587549924...|\n",
      "|  0.0|         [Waistband]|[0.10752370953559...|\n",
      "|  1.0|            [Tutus!]|[0.01405739784240...|\n",
      "|  1.0|      [Very, happy!]|[-0.3688471466302...|\n",
      "|  1.0|[Perfect, for, th...|[0.09724645316600...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1dc3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47940fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data to train and test, 80% is for training and the rest is for tesing.\n",
    "train, test = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af38d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define decision tree and its hyper parameters for grid searching.\n",
    "dt = DecisionTreeClassifier(featuresCol= 'features', labelCol = 'label')\n",
    "\n",
    "dtParamGrid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.minInstancesPerNode, [3, 5, 10, 15]) \\\n",
    "    .addGrid(dt.maxDepth, [3, 5, 10, 20]) \\\n",
    "    .addGrid(dt.maxBins, [8, 16, 32])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using grid search to find best hyper parameter. The evaluation strategy is k-fold cross validation, in our case,\n",
    "# k equals 5. In other words, each hyper parameters set is evaluated by 5-fold cross validation on traing data.  \n",
    "# The best model is tested on test data, results are following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf8ba2c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bestDT \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m(train, dt, dtParamGrid)\n\u001b[1;32m      3\u001b[0m acc, confusion, precision, reall \u001b[38;5;241m=\u001b[39m evaluateModel(test, bestDT)\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainModel' is not defined"
     ]
    }
   ],
   "source": [
    "bestDT = trainModel(train, dt, dtParamGrid)\n",
    "\n",
    "acc, confusion, precision, reall = evaluateModel(test, bestDT)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.heatmap(confusion, annot= True, cmap=\"PuBu\", ax = ax, fmt= '.0f')\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Ground Truth\")\n",
    "ax.set_yticklabels([\"No\", \"Yes\"])\n",
    "ax.set_xticklabels([\"No\", \"Yes\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e9768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
